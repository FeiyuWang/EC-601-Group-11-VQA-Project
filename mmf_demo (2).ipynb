{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mmf_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf1a2281ad284ca188ed65cacbcfb36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd4443e924a54f8d8dc30fd38abc32ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0188844f10c84acfbe4da23cd55539b2",
              "IPY_MODEL_16d9769b6049457080e9a443e0ea9e83"
            ]
          }
        },
        "dd4443e924a54f8d8dc30fd38abc32ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0188844f10c84acfbe4da23cd55539b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbb8fd42eac24f62b162b35ea0b2a496",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241627721,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241627721,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6071ad8f6f0b4cbfa1c64aa9582991e2"
          }
        },
        "16d9769b6049457080e9a443e0ea9e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b53cad8ff7dd4b288c6919e754e45432",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:05&lt;00:00, 45.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbd212b6e40041d485bb4ed0e473339e"
          }
        },
        "fbb8fd42eac24f62b162b35ea0b2a496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6071ad8f6f0b4cbfa1c64aa9582991e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b53cad8ff7dd4b288c6919e754e45432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbd212b6e40041d485bb4ed0e473339e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b71e9e1dad14ca8867d680dae8c9301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55b8002425554edfbcf9b7102c70e758",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5d4c1fba69643a081cb307b1fbda8ca",
              "IPY_MODEL_94bb2a87ff3f4b23bc1ffe32e063eeca"
            ]
          }
        },
        "55b8002425554edfbcf9b7102c70e758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5d4c1fba69643a081cb307b1fbda8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6517ce782e034ec5b095df9fe79415fa",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 117217582,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 117217582,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15de14ba638f4d3f912a88c319eefcb0"
          }
        },
        "94bb2a87ff3f4b23bc1ffe32e063eeca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cd7438011d0e45578369836d691a82a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112M/112M [02:00&lt;00:00, 970kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b616466f0394e0cb18dbc616ed0488f"
          }
        },
        "6517ce782e034ec5b095df9fe79415fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15de14ba638f4d3f912a88c319eefcb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd7438011d0e45578369836d691a82a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b616466f0394e0cb18dbc616ed0488f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "468497a4a6134334940a51d01a984a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_4e7a09fa0f7645b9b9d00a07871925b8",
            "_dom_classes": [],
            "description": "Image URL",
            "_model_name": "TextModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "VizWiz_val_00028000.jpg",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6c63b88c84b4e2994c2991fc0d61341"
          }
        },
        "4e7a09fa0f7645b9b9d00a07871925b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6c63b88c84b4e2994c2991fc0d61341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98a7eb4d20714414a62b1cd8f1d7ab5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_17ce9213468b40958034f0b2d1aa7ef4",
            "_dom_classes": [],
            "description": "Question",
            "_model_name": "TextModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "hello helhallo",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1c395c7c5de45dcb2707797b3e2807a"
          }
        },
        "17ce9213468b40958034f0b2d1aa7ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1c395c7c5de45dcb2707797b3e2807a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ac61d35f4544258a49f224f7a3859ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_995b7e9ced6a49da90e0b5acc11e2df0",
            "_dom_classes": [],
            "description": "Ask MMF!",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_aac370e61f0a44a69f8d7442f7b1d868",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "995b7e9ced6a49da90e0b5acc11e2df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aac370e61f0a44a69f8d7442f7b1d868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXeEePmeEuuY"
      },
      "source": [
        "## First download all of the necessary data\n",
        "\n",
        "---\n",
        "\n",
        "Press \"Shift + Enter\" to run each cell sequentially. Alternatively, you can press \"Cmd/Ctrl + F9\" to run all cells and then scroll down to bottom cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRUp0r_-B9N0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1063776-223d-43f6-a142-4fd7200cca74"
      },
      "source": [
        "# Download Pre-requisites needed for running the e2e model\n",
        "%cd /content/\n",
        "\n",
        "%mkdir model_data\n",
        "!wget -O /content/model_data/answers_vqa.txt https://dl.fbaipublicfiles.com/pythia/data/answers_vqa.txt\n",
        "!wget -O /content/model_data/vocabulary_100k.txt https://dl.fbaipublicfiles.com/pythia/data/vocabulary_100k.txt\n",
        "!wget -O /content/model_data/detectron_model.pth  https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model.pth \n",
        "!wget -O /content/model_data/pythia.pth https://dl.fbaipublicfiles.com/pythia/pretrained_models/vqa2/pythia_train_val.pth\n",
        "!wget -O /content/model_data/pythia.yaml https://dl.fbaipublicfiles.com/pythia/pretrained_models/vqa2/pythia_train_val.yml\n",
        "!wget -O /content/model_data/detectron_model.yaml https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model.yaml\n",
        "!wget -O /content/model_data/detectron_weights.tar.gz https://dl.fbaipublicfiles.com/pythia/data/detectron_weights.tar.gz\n",
        "!tar xf /content/model_data/detectron_weights.tar.gz"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "mkdir: cannot create directory â€˜model_dataâ€™: File exists\n",
            "--2021-11-28 18:10:33--  https://dl.fbaipublicfiles.com/pythia/data/answers_vqa.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24768 (24K) [text/plain]\n",
            "Saving to: â€˜/content/model_data/answers_vqa.txtâ€™\n",
            "\n",
            "/content/model_data 100%[===================>]  24.19K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-11-28 18:10:34 (407 KB/s) - â€˜/content/model_data/answers_vqa.txtâ€™ saved [24768/24768]\n",
            "\n",
            "--2021-11-28 18:10:34--  https://dl.fbaipublicfiles.com/pythia/data/vocabulary_100k.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 626738 (612K) [text/plain]\n",
            "Saving to: â€˜/content/model_data/vocabulary_100k.txtâ€™\n",
            "\n",
            "/content/model_data 100%[===================>] 612.05K  1.94MB/s    in 0.3s    \n",
            "\n",
            "2021-11-28 18:10:35 (1.94 MB/s) - â€˜/content/model_data/vocabulary_100k.txtâ€™ saved [626738/626738]\n",
            "\n",
            "--2021-11-28 18:10:35--  https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 684079216 (652M) [application/octet-stream]\n",
            "Saving to: â€˜/content/model_data/detectron_model.pthâ€™\n",
            "\n",
            "/content/model_data 100%[===================>] 652.39M  31.2MB/s    in 21s     \n",
            "\n",
            "2021-11-28 18:10:57 (30.6 MB/s) - â€˜/content/model_data/detectron_model.pthâ€™ saved [684079216/684079216]\n",
            "\n",
            "--2021-11-28 18:10:57--  https://dl.fbaipublicfiles.com/pythia/pretrained_models/vqa2/pythia_train_val.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 713440524 (680M) [application/octet-stream]\n",
            "Saving to: â€˜/content/model_data/pythia.pthâ€™\n",
            "\n",
            "/content/model_data 100%[===================>] 680.39M  29.2MB/s    in 24s     \n",
            "\n",
            "2021-11-28 18:11:21 (28.6 MB/s) - â€˜/content/model_data/pythia.pthâ€™ saved [713440524/713440524]\n",
            "\n",
            "--2021-11-28 18:11:22--  https://dl.fbaipublicfiles.com/pythia/pretrained_models/vqa2/pythia_train_val.yml\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6577 (6.4K) [text/plain]\n",
            "Saving to: â€˜/content/model_data/pythia.yamlâ€™\n",
            "\n",
            "/content/model_data 100%[===================>]   6.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-28 18:11:22 (51.4 MB/s) - â€˜/content/model_data/pythia.yamlâ€™ saved [6577/6577]\n",
            "\n",
            "--2021-11-28 18:11:22--  https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model.yaml\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 918 [text/plain]\n",
            "Saving to: â€˜/content/model_data/detectron_model.yamlâ€™\n",
            "\n",
            "/content/model_data 100%[===================>]     918  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-28 18:11:23 (10.2 MB/s) - â€˜/content/model_data/detectron_model.yamlâ€™ saved [918/918]\n",
            "\n",
            "--2021-11-28 18:11:23--  https://dl.fbaipublicfiles.com/pythia/data/detectron_weights.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31091524 (30M) [application/gzip]\n",
            "Saving to: â€˜/content/model_data/detectron_weights.tar.gzâ€™\n",
            "\n",
            "/content/model_data 100%[===================>]  29.65M  20.9MB/s    in 1.4s    \n",
            "\n",
            "2021-11-28 18:11:25 (20.9 MB/s) - â€˜/content/model_data/detectron_weights.tar.gzâ€™ saved [31091524/31091524]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4S01cUqE3WJ"
      },
      "source": [
        "## Now, install some particular dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQCyXjYyFQzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1128de8-b6e8-442c-f5cb-8a84c035d735"
      },
      "source": [
        "# Install dependencies\n",
        "!pip install yacs cython matplotlib\n",
        "!pip install git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
        "!pip3 install --upgrade Pillow\n",
        "!pip install gTTS\n",
        "!pip install pygame\n",
        "!pip install -q torchaudio omegaconf soundfile\n",
        "!pip install ffmpeg"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (0.1.8)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.24)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.3.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from yacs) (6.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-nh20trhf\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-nh20trhf\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.24)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.3.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (8.4.0)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gTTS) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gTTS) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gTTS) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2021.10.8)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.7/dist-packages (1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivSdn9BFFpxp"
      },
      "source": [
        "## Install MMF now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOHchoDW7yqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a676a1f1-8fb8-4a06-f1bd-2c2f0de285c2"
      },
      "source": [
        "%cd /content/\n",
        "%rm -rf mmf\n",
        "!git clone https://github.com/facebookresearch/mmf.git mmf\n",
        "%cd /content/mmf\n",
        "# Don't modify torch version\n",
        "!sed -i '/torch/d' requirements.txt\n",
        "!pip install -e .\n",
        "import sys\n",
        "sys.path.append(\"/content/mmf\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'mmf'...\n",
            "remote: Enumerating objects: 23164, done.\u001b[K\n",
            "remote: Counting objects: 100% (3107/3107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1113/1113), done.\u001b[K\n",
            "remote: Total 23164 (delta 2128), reused 2602 (delta 1712), pack-reused 20057\u001b[K\n",
            "Receiving objects: 100% (23164/23164), 16.81 MiB | 14.62 MiB/s, done.\n",
            "Resolving deltas: 100% (14941/14941), done.\n",
            "/content/mmf\n",
            "Obtaining file:///content/mmf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 104, in resolve\n",
            "    req, requested_extras=()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 434, in make_requirement_from_install_req\n",
            "    version=None,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 190, in _make_candidate_from_link\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 340, in __init__\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 151, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 234, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 345, in _prepare_distribution\n",
            "    return self._factory.preparer.prepare_editable_requirement(self._ireq)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 626, in prepare_editable_requirement\n",
            "    req.check_if_exists(self.use_user_site)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_install.py\", line 418, in check_if_exists\n",
            "    existing_dist = get_distribution(self.req.name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/misc.py\", line 432, in get_distribution\n",
            "    dist = get_default_environment().get_distribution(req_name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 118, in get_distribution\n",
            "    self._ws.require(name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 900, in require\n",
            "    needed = self.resolve(parse_requirements(requirements))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 791, in resolve\n",
            "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
            "pip._vendor.pkg_resources.ContextualVersionConflict: (Pillow 8.4.0 (/usr/local/lib/python3.7/dist-packages), Requirement.parse('pillow==8.3.1'), {'mmf'})\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5o-zqvuFxeR"
      },
      "source": [
        "## Install maskrcnn-benchmark now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ROyH7yG11V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb2393f-3f72-41e3-cb0b-30fca0ece6d2"
      },
      "source": [
        "# Install maskrcnn-benchmark to extract detectron features\n",
        "%cd /content\n",
        "!git clone https://gitlab.com/meetshah1995/vqa-maskrcnn-benchmark.git\n",
        "%cd /content/vqa-maskrcnn-benchmark\n",
        "# Compile custom layers and build mask-rcnn backbone\n",
        "!python setup.py build\n",
        "!python setup.py develop\n",
        "sys.path.append('/content/vqa-maskrcnn-benchmark')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'vqa-maskrcnn-benchmark' already exists and is not an empty directory.\n",
            "/content/vqa-maskrcnn-benchmark\n",
            "running build\n",
            "running build_py\n",
            "running build_ext\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "running develop\n",
            "running egg_info\n",
            "writing maskrcnn_benchmark.egg-info/PKG-INFO\n",
            "writing dependency_links to maskrcnn_benchmark.egg-info/dependency_links.txt\n",
            "writing top-level names to maskrcnn_benchmark.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.7/maskrcnn_benchmark/_C.cpython-37m-x86_64-linux-gnu.so -> maskrcnn_benchmark\n",
            "Creating /usr/local/lib/python3.7/dist-packages/maskrcnn-benchmark.egg-link (link to .)\n",
            "maskrcnn-benchmark 0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /content/vqa-maskrcnn-benchmark\n",
            "Processing dependencies for maskrcnn-benchmark==0.1\n",
            "Finished processing dependencies for maskrcnn-benchmark==0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEb_d9pcyYXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc44f6c0-7ffe-443e-e9ad-29c2d107a5df"
      },
      "source": [
        "#cat imports.py\n",
        "!pip install sentencepiece\n",
        "!pip install numpy\n",
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting git+https://github.com/PyTorchLightning/pytorch-lightning\n",
            "  Cloning https://github.com/PyTorchLightning/pytorch-lightning to /tmp/pip-req-build-fpp8tdv2\n",
            "  Running command git clone -q https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-req-build-fpp8tdv2\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (4.0.0)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (1.10.0+cu111)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (0.18.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (21.3)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (0.6.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (4.49.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (6.0)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (0.3.1)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (2021.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.6.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.35.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (21.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (4.0.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (5.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yx6FeDEF2sw"
      },
      "source": [
        "## Demo\n",
        "\n",
        "The class handles everything from feature extraction, token extraction and predicting the answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCD0nso8YelA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb22b1e-905b-4a54-d4ea-3cd3778712ca"
      },
      "source": [
        "%cd /content/\n",
        "import yaml\n",
        "import cv2\n",
        "import torch\n",
        "import requests\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from ipywidgets import widgets, Layout\n",
        "from io import BytesIO\n",
        "from argparse import Namespace\n",
        "\n",
        "\n",
        "from maskrcnn_benchmark.config import cfg\n",
        "from maskrcnn_benchmark.layers import nms\n",
        "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
        "from maskrcnn_benchmark.structures.image_list import to_image_list\n",
        "from maskrcnn_benchmark.utils.model_serialization import load_state_dict\n",
        "\n",
        "\n",
        "from mmf.datasets.processors.processors import VocabProcessor, VQAAnswerProcessor\n",
        "from mmf.models.pythia import Pythia\n",
        "from mmf.common.registry import registry\n",
        "from mmf.common.sample import Sample, SampleList\n",
        "from mmf.utils.env import setup_imports\n",
        "from mmf.utils.configuration import Configuration\n",
        "\n",
        "setup_imports()\n",
        "\n",
        "class MMFDemo:\n",
        "  TARGET_IMAGE_SIZE = [448, 448]\n",
        "  CHANNEL_MEAN = [0.485, 0.456, 0.406]\n",
        "  CHANNEL_STD = [0.229, 0.224, 0.225]\n",
        "  \n",
        "  def __init__(self):\n",
        "    self._init_processors()\n",
        "    self.pythia_model = self._build_pythia_model()\n",
        "    self.detection_model = self._build_detection_model()\n",
        "    self.resnet_model = self._build_resnet_model()\n",
        "    \n",
        "  def _init_processors(self):\n",
        "    args = Namespace()\n",
        "    args.opts = [\n",
        "        \"config=projects/pythia/configs/vqa2/defaults.yaml\",\n",
        "        \"datasets=vqa2\",\n",
        "        \"model=pythia\",\n",
        "        \"evaluation.predict=True\"\n",
        "    ]\n",
        "    args.config_override = None\n",
        "\n",
        "    configuration = Configuration(args=args)\n",
        "    \n",
        "    config = self.config = configuration.config\n",
        "    vqa_config = config.dataset_config.vqa2\n",
        "    text_processor_config = vqa_config.processors.text_processor\n",
        "    answer_processor_config = vqa_config.processors.answer_processor\n",
        "    \n",
        "    text_processor_config.params.vocab.vocab_file = \"/content/model_data/vocabulary_100k.txt\"\n",
        "    answer_processor_config.params.vocab_file = \"/content/model_data/answers_vqa.txt\"\n",
        "    # Add preprocessor as that will needed when we are getting questions from user\n",
        "    self.text_processor = VocabProcessor(text_processor_config.params)\n",
        "    self.answer_processor = VQAAnswerProcessor(answer_processor_config.params)\n",
        "\n",
        "    registry.register(\"vqa2_text_processor\", self.text_processor)\n",
        "    registry.register(\"vqa2_answer_processor\", self.answer_processor)\n",
        "    registry.register(\"vqa2_num_final_outputs\", \n",
        "                      self.answer_processor.get_vocab_size())\n",
        "    \n",
        "  def _build_pythia_model(self):\n",
        "    state_dict = torch.load('/content/model_data/pythia.pth')\n",
        "    model_config = self.config.model_config.pythia\n",
        "    model_config.model_data_dir = \"/content/\"\n",
        "    model = Pythia(model_config)\n",
        "    model.build()\n",
        "    model.init_losses()\n",
        "    \n",
        "    if list(state_dict.keys())[0].startswith('module') and \\\n",
        "       not hasattr(model, 'module'):\n",
        "      state_dict = self._multi_gpu_state_to_single(state_dict)\n",
        "          \n",
        "    model.load_state_dict(state_dict, strict=False)\n",
        "    model.to(\"cuda\")\n",
        "    model.eval()\n",
        "    \n",
        "    return model\n",
        "  \n",
        "  def _build_resnet_model(self):\n",
        "    self.data_transforms = transforms.Compose([\n",
        "        transforms.Resize(self.TARGET_IMAGE_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(self.CHANNEL_MEAN, self.CHANNEL_STD),\n",
        "    ])\n",
        "    resnet152 = models.resnet152(pretrained=True)\n",
        "    resnet152.eval()\n",
        "    modules = list(resnet152.children())[:-2]\n",
        "    self.resnet152_model = torch.nn.Sequential(*modules)\n",
        "    self.resnet152_model.to(\"cuda\")\n",
        "  \n",
        "  def _multi_gpu_state_to_single(self, state_dict):\n",
        "    new_sd = {}\n",
        "    for k, v in state_dict.items():\n",
        "        if not k.startswith('module.'):\n",
        "            raise TypeError(\"Not a multiple GPU state of dict\")\n",
        "        k1 = k[7:]\n",
        "        new_sd[k1] = v\n",
        "    return new_sd\n",
        "  \n",
        "  def predict(self, url, question):\n",
        "    with torch.no_grad():\n",
        "      detectron_features = self.get_detectron_features(url)\n",
        "      resnet_features = self.get_resnet_features(url)\n",
        "\n",
        "      sample = Sample()\n",
        "\n",
        "      processed_text = self.text_processor({\"text\": question})\n",
        "      sample.text = processed_text[\"text\"]\n",
        "      sample.text_len = len(processed_text[\"tokens\"])\n",
        "\n",
        "      sample.image_feature_0 = detectron_features\n",
        "      sample.image_info_0 = Sample({\n",
        "          \"max_features\": torch.tensor(100, dtype=torch.long)\n",
        "      })\n",
        "\n",
        "      sample.image_feature_1 = resnet_features\n",
        "\n",
        "      sample_list = SampleList([sample])\n",
        "      sample_list = sample_list.to(\"cuda\")\n",
        "\n",
        "      scores = self.pythia_model(sample_list)[\"scores\"]\n",
        "      scores = torch.nn.functional.softmax(scores, dim=1)\n",
        "      actual, indices = scores.topk(5, dim=1)\n",
        "\n",
        "      top_indices = indices[0]\n",
        "      top_scores = actual[0]\n",
        "\n",
        "      probs = []\n",
        "      answers = []\n",
        "\n",
        "      for idx, score in enumerate(top_scores):\n",
        "        probs.append(score.item())\n",
        "        answers.append(\n",
        "            self.answer_processor.idx2word(top_indices[idx].item())\n",
        "        )\n",
        "    \n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    return probs, answers\n",
        "    \n",
        "  \n",
        "  def _build_detection_model(self):\n",
        "\n",
        "      cfg.merge_from_file('/content/model_data/detectron_model.yaml')\n",
        "      cfg.freeze()\n",
        "\n",
        "      model = build_detection_model(cfg)\n",
        "      checkpoint = torch.load('/content/model_data/detectron_model.pth', \n",
        "                              map_location=torch.device(\"cpu\"))\n",
        "\n",
        "      load_state_dict(model, checkpoint.pop(\"model\"))\n",
        "\n",
        "      model.to(\"cuda\")\n",
        "      model.eval()\n",
        "      return model\n",
        "  \n",
        "  def get_actual_image(self, image_path):\n",
        "      if image_path.startswith('http'):\n",
        "          path = requests.get(image_path, stream=True).raw\n",
        "      else:\n",
        "          path = image_path\n",
        "      \n",
        "      return path\n",
        "\n",
        "  def _image_transform(self, image_path):\n",
        "      path = self.get_actual_image(image_path)\n",
        "\n",
        "      img = Image.open(path)\n",
        "      im = np.array(img).astype(np.float32)\n",
        "      im = im[:, :, ::-1]\n",
        "      im -= np.array([102.9801, 115.9465, 122.7717])\n",
        "      im_shape = im.shape\n",
        "      im_size_min = np.min(im_shape[0:2])\n",
        "      im_size_max = np.max(im_shape[0:2])\n",
        "      im_scale = float(800) / float(im_size_min)\n",
        "      # Prevent the biggest axis from being more than max_size\n",
        "      if np.round(im_scale * im_size_max) > 1333:\n",
        "           im_scale = float(1333) / float(im_size_max)\n",
        "      im = cv2.resize(\n",
        "           im,\n",
        "           None,\n",
        "           None,\n",
        "           fx=im_scale,\n",
        "           fy=im_scale,\n",
        "           interpolation=cv2.INTER_LINEAR\n",
        "       )\n",
        "      img = torch.from_numpy(im).permute(2, 0, 1)\n",
        "      return img, im_scale\n",
        "\n",
        "\n",
        "  def _process_feature_extraction(self, output,\n",
        "                                 im_scales,\n",
        "                                 feat_name='fc6',\n",
        "                                 conf_thresh=0.2):\n",
        "      batch_size = len(output[0][\"proposals\"])\n",
        "      n_boxes_per_image = [len(_) for _ in output[0][\"proposals\"]]\n",
        "      score_list = output[0][\"scores\"].split(n_boxes_per_image)\n",
        "      score_list = [torch.nn.functional.softmax(x, -1) for x in score_list]\n",
        "      feats = output[0][feat_name].split(n_boxes_per_image)\n",
        "      cur_device = score_list[0].device\n",
        "\n",
        "      feat_list = []\n",
        "\n",
        "      for i in range(batch_size):\n",
        "          dets = output[0][\"proposals\"][i].bbox / im_scales[i]\n",
        "          scores = score_list[i]\n",
        "\n",
        "          max_conf = torch.zeros((scores.shape[0])).to(cur_device)\n",
        "\n",
        "          for cls_ind in range(1, scores.shape[1]):\n",
        "              cls_scores = scores[:, cls_ind]\n",
        "              keep = nms(dets, cls_scores, 0.5)\n",
        "              max_conf[keep] = torch.where(cls_scores[keep] > max_conf[keep],\n",
        "                                           cls_scores[keep],\n",
        "                                           max_conf[keep])\n",
        "\n",
        "          keep_boxes = torch.argsort(max_conf, descending=True)[:100]\n",
        "          feat_list.append(feats[i][keep_boxes])\n",
        "      return feat_list\n",
        "\n",
        "  def masked_unk_softmax(self, x, dim, mask_idx):\n",
        "      x1 = F.softmax(x, dim=dim)\n",
        "      x1[:, mask_idx] = 0\n",
        "      x1_sum = torch.sum(x1, dim=1, keepdim=True)\n",
        "      y = x1 / x1_sum\n",
        "      return y\n",
        "   \n",
        "  def get_resnet_features(self, image_path):\n",
        "      path = self.get_actual_image(image_path)\n",
        "      img = Image.open(path).convert(\"RGB\")\n",
        "      img_transform = self.data_transforms(img)\n",
        "      \n",
        "      if img_transform.shape[0] == 1:\n",
        "        img_transform = img_transform.expand(3, -1, -1)\n",
        "      img_transform = img_transform.unsqueeze(0).to(\"cuda\")\n",
        "      \n",
        "      features = self.resnet152_model(img_transform).permute(0, 2, 3, 1)\n",
        "      features = features.view(196, 2048)\n",
        "      return features\n",
        "    \n",
        "  def get_detectron_features(self, image_path):\n",
        "      im, im_scale = self._image_transform(image_path)\n",
        "      img_tensor, im_scales = [im], [im_scale]\n",
        "      current_img_list = to_image_list(img_tensor, size_divisible=32)\n",
        "      current_img_list = current_img_list.to('cuda')\n",
        "      with torch.no_grad():\n",
        "          output = self.detection_model(current_img_list)\n",
        "      feat_list = self._process_feature_extraction(output, im_scales, \n",
        "                                                  'fc6', 0.2)\n",
        "      return feat_list[0]\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3IanIVPt91G"
      },
      "source": [
        "### If the command below fails with 'CUDNN_EXECUTION_FAILED', try rerunning the cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwF36OmQ72ir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "bf1a2281ad284ca188ed65cacbcfb36d",
            "dd4443e924a54f8d8dc30fd38abc32ba",
            "0188844f10c84acfbe4da23cd55539b2",
            "16d9769b6049457080e9a443e0ea9e83",
            "fbb8fd42eac24f62b162b35ea0b2a496",
            "6071ad8f6f0b4cbfa1c64aa9582991e2",
            "b53cad8ff7dd4b288c6919e754e45432",
            "fbd212b6e40041d485bb4ed0e473339e"
          ]
        },
        "outputId": "9ba8154d-a519-485f-f07f-d2d90294fa26"
      },
      "source": [
        "demo = MMFDemo()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n",
            "  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf1a2281ad284ca188ed65cacbcfb36d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241627721.0), HTML(value='')))"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CinwDLv5GLJI"
      },
      "source": [
        "## Use the text fields below to ask a question on an image\n",
        "\n",
        "Image URL can be any http/https URL. We show top 5 predictions from MMF. Confidence shows how confident MMF model was about a particular prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_55MoLFlhL4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "2b71e9e1dad14ca8867d680dae8c9301",
            "55b8002425554edfbcf9b7102c70e758",
            "e5d4c1fba69643a081cb307b1fbda8ca",
            "94bb2a87ff3f4b23bc1ffe32e063eeca",
            "6517ce782e034ec5b095df9fe79415fa",
            "15de14ba638f4d3f912a88c319eefcb0",
            "cd7438011d0e45578369836d691a82a7",
            "4b616466f0394e0cb18dbc616ed0488f",
            "468497a4a6134334940a51d01a984a94",
            "4e7a09fa0f7645b9b9d00a07871925b8",
            "b6c63b88c84b4e2994c2991fc0d61341",
            "98a7eb4d20714414a62b1cd8f1d7ab5b",
            "17ce9213468b40958034f0b2d1aa7ef4",
            "d1c395c7c5de45dcb2707797b3e2807a",
            "3ac61d35f4544258a49f224f7a3859ee",
            "995b7e9ced6a49da90e0b5acc11e2df0",
            "aac370e61f0a44a69f8d7442f7b1d868"
          ]
        },
        "outputId": "e38938c5-15f1-4acf-bb3e-38e4adf45962"
      },
      "source": [
        "from gtts import gTTS\n",
        "import pygame\n",
        "import os\n",
        "import torch\n",
        "import zipfile\n",
        "import torchaudio\n",
        "from glob import glob\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "def init_widgets(url, question):\n",
        "  image_text = widgets.Text(\n",
        "    description=\"Image URL\", layout=Layout(minwidth=\"70%\")\n",
        "  )\n",
        "  question_text = widgets.Text(\n",
        "      description=\"Question\", layout=Layout(minwidth=\"70%\")\n",
        "  )\n",
        "\n",
        "  image_text.value = url\n",
        "  question_text.value = question\n",
        "  submit_button = widgets.Button(description=\"Ask MMF!\")\n",
        "\n",
        "  display(image_text)\n",
        "  display(question_text)\n",
        "  display(submit_button)\n",
        "\n",
        "  submit_button.on_click(lambda b: on_button_click(\n",
        "      b, image_text, question_text\n",
        "  ))\n",
        "  \n",
        "  return image_text, question_text\n",
        "  \n",
        "def on_button_click(b, image_text, question_text):\n",
        "  clear_output()\n",
        "  image_path = demo.get_actual_image(image_text.value)\n",
        "  image = Image.open(image_path)\n",
        "  \n",
        "  scores, predictions = demo.predict(image_text.value, question_text.value)\n",
        "  scores = [score * 100 for score in scores]\n",
        "  df = pd.DataFrame({\n",
        "      \"Prediction\": predictions,\n",
        "      \"Confidence\": scores\n",
        "  })\n",
        "  language = 'en'\n",
        "  myobj = gTTS(text=predictions[0], lang=language, slow=False)\n",
        "  myobj.save(\"output.mp3\")\n",
        "  '''\n",
        "  pygame.mixer.init()\n",
        "  pygame.mixer.music.load('output.mp3')\n",
        "  pygame.mixer.music.play()\n",
        "  '''\n",
        "  init_widgets(image_text.value, question_text.value)\n",
        "  display(image)\n",
        "  display(HTML(df.to_html()))\n",
        " \n",
        "s = \"\"\n",
        "\n",
        "wav_audio = AudioSegment.from_file(\"Recording.m4a\", format=\"m4a\")\n",
        "wav_audio.export(\"recording.wav\", format=\"wav\")    \n",
        "\n",
        "device = torch.device('cpu')  # gpu also works, but our models are fast enough for CPU\n",
        "\n",
        "model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                       model='silero_stt',\n",
        "                                       language='en', # also available 'de', 'es'\n",
        "                                       device=device)\n",
        "(read_batch, split_into_batches,\n",
        " read_audio, prepare_model_input) = utils  # see function signature for details\n",
        "\n",
        "test_files = glob('recording.wav')\n",
        "batches = split_into_batches(test_files, batch_size=10)\n",
        "input = prepare_model_input(read_batch(batches[0]),\n",
        "                            device=device)\n",
        "\n",
        "output = model(input)\n",
        "for example in output:\n",
        "    s = decoder(example.cpu())\n",
        "\n",
        "\n",
        "image_text, question_text = init_widgets(\n",
        "    \"VizWiz_val_00028000.jpg\", \n",
        "    s\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/snakers4/silero-models/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b71e9e1dad14ca8867d680dae8c9301",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=117217582.0), HTML(value='')))"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "468497a4a6134334940a51d01a984a94",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='VizWiz_val_00028000.jpg', description='Image URL')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98a7eb4d20714414a62b1cd8f1d7ab5b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='hello helhallo', description='Question')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ac61d35f4544258a49f224f7a3859ee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Button(description='Ask MMF!', style=ButtonStyle())"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}